# IOR + libompfile (minimal prototype)

## What is implemented

- A minimal IOR backend adapter is available at `src/aiori-ompfile.c`.
- The backend maps IOR open/read/write/close hooks to:
  - `omp_file_open`
  - `omp_file_pread`
  - `omp_file_pwrite`
  - `omp_file_close`
- File-size checks used by IOR validation are implemented with `stat(2)`.

## Minimal requirements

- LLVM runtime build with `libompfile` available.
- MPI launcher/runtime (MPICH in this workspace).
- `llvm-offload-mpi-proxy-device` built at:
  - `${LLVM_ROOT}/bin/llvm-offload-mpi-proxy-device`
- Environment setup:
  - `source sh-scripts/set_env.sh <LLVM_ROOT>`
  - `bash sh-scripts/register_mpi_clang.sh`

## Compile

From repo root:

```bash
source sh-scripts/set_env.sh /scratch/rodrigo.freitas/io-playground/llvm-infra/llvm-builds/apptainer-Debug
bash sh-scripts/register_mpi_clang.sh
cd application/ior-fork
CPPFLAGS="-I/scratch/rodrigo.freitas/io-playground/llvm-infra/llvm-installs/apptainer-Debug/include" \
LDFLAGS="-L/scratch/rodrigo.freitas/io-playground/llvm-infra/llvm-builds/apptainer-Debug/runtimes/runtimes-bins/openmp/libompfile" \
./configure CC=mpi_clang
make -j
```

## Local smoke run (single process)

```bash
cd application/ior-fork
block_size=4m ior_mode=ompfile_mpi_io read_or_write=read ./run.sh
```

## MPP prototype run (one app rank + proxy ranks)

Use one IOR app rank plus proxy ranks in the same MPI world.

Key behavior in this prototype:

- App rank runs IOR with `IOR_MPI_COMM_SELF=1`.
- Proxy ranks run `llvm-offload-mpi-proxy-device`.
- This avoids IOR collectives blocking on proxy ranks.

Slurm example:

```bash
sbatch /scratch/rodrigo.freitas/io-playground/application/ior-fork/run_sorgan_ior_mpp_minimal.sbatch
```

## MPI plan / execution flow

1. Start one MPI job with `N` ranks.
2. Reserve rank `N-1` as app rank; all lower ranks become proxy ranks.
3. App rank executes IOR (`-a OMPFILE`) with `IOR_MPI_COMM_SELF=1`.
4. Proxy ranks execute `llvm-offload-mpi-proxy-device`.
5. libompfile MPP path routes OMPFILE operations from the app rank to proxy workers.

## Current limitations

- This is a minimal prototype for integration and bring-up.
- IOR MPI collectives are intentionally scoped to `MPI_COMM_SELF` in MPP mode.
- Performance/scaling results from this mode are not yet representative of full
  multi-rank IOR semantics.
- Current split-role MPP runs still fail in pure IOR processes with
  `ompfile_mpp_init rc=-1` (`ActiveMPIPlugin` initialization path unresolved
  without an offload-enabled app/runtime bootstrap).
